{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])"},"docs":[{"location":"","text":"1. Introduction 1.1.Business Understanding Currently music on-line platform is on the rise. However people still can't fully developed shared their taste. Our Founder feel those and start to develop Music Streaming Platform called ontrack . Our Business is based on Subscription Model. Our Catalogue is Quite Huge contain ~17632 Artists. Our business is on decline, previous month we serve nearly 5000 users, however there is significant churn leaving our platform only having ~2000 users. We are in data science team,asked to assist business development team to tackle this situation. 1.2. Problem Definition Business Process Problem : User Churn ~60% ! 1.3. Business Metrics Business Metrics : Churn Rate 1.4. Identifying Machine Learning Problem Process that could be helped with machine learning : Possible Solutions : | No | Solution | Task | Detailed Task | Metrics | |---:|------------------------------------------------------:|---------------:|-----------------------|--------------------------------------------------------| | 1 | Predict number of user play count on each artist | Regression | Count Regression | Prediction Error (RMSE,MAE,etc) | | 2 | Predict whether user will like the artist or not | Classification | Binary Classification | Decision Support Metrics (Precision,Recall,AUC,F1,etc) | | 3 | Predict condfidence scale (0-1) how user like an item | Regression | - | Prediction Error (RMSE,MAE,etc) | | 4 | Predict the ranking from user to artists | Ranking | Pairwise Ranking | Ranking Metrics (ex : NDCG,MAP,MRR,etc) | 1.5 Objective Metrics 2. Related Work Hu, Y., Ogihara, M.: Nextone player: A music recommendation system based on user behaviour. In: Int. Society for Music Information Retrieval Conf. (ISMIR\u201911) (2011) Hariri, N., Mobasher, B., Burke, R.: Context-aware music recommendation based on latenttopic sequential patterns. In: Proceedings of the sixth ACM conference on Recommender systems, pp. 131\u2013138. ACM (2012) 3. Dataset and Features The dataset obtained from http://www.last.fm, online music system. The dataset itself contains several files artists.dat Contains features : - `name` - `url` - `pictureURL` tags.dat Contains features : - `tagID` - `tagValue` user_artists.dat Contains features : - `userID` - `artistsID` - `pictureURL` user_friends.dat Contains features : - `name` - `url` - `pictureURL` user_taggedartists.dat Contains features : - `name` - `url` - `pictureURL` 4. Methods 4.1. Recommender System Introduction Recomender system Problem We have implicit feedback dataset that reflects number of user plays from certain artist. Given those utility matrix we will recommend to each user what artist they might like. The recommendation will be in form such as 1. \"Since you listen to artist X\" --> give list 2. etc. Since we have enough utility matrix / implicit feedback we will start with collaborative filtering approach. Collaborative filtering approach can be divided into several approaches 4.2.Baseline (Popularity Recommendation) 4.3. Alternating Least Square (Implicit Feedback Matrix Factorization) Hu, Yifan, Yehuda Koren, and Chris Volinsky. 2008. \u201cCollaborative Filtering for Implicit Feedback Datasets.\u201d In 2008 Eighth IEEE International Conference on Data Mining, 263\u201372. IEEE. 4.3. Bayesian Personalized Ranking Rendle, Steffen, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. \u201cBPR: Bayesian Personalized Ranking from Implicit Feedback.\u201d In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, 452\u201361. AUAI Press. 4.4. Logistic Matrix Factorization Johnson, Christopher C. 2014. \u201cLogistic Matrix Factorization for Implicit Feedback Data.\u201d Advances in Neural Information Processing Systems 27. 5.Experiments / Results / Discussion 5.1. Data Splitting Strategy 5.2. Data Preprocessing 5.2.1 Mapping userID & artistsID into Ordered ID Our data requirement is in utility matrix form, it would be hard to access each element in utility matrix since utility matrix has ordered id. We need to create mapping for both userID, artistsID to orderedID and vice versa.Our Mapping is in python dictionary object. user_id_to_ordered_id = { userID:ordereduserID } example : user_id_to_ordered_id = { 2:1 } for later usage (such as : API) we will serialize object using joblib.dump function as pickle file ( .pkl ), named : 1. user_id_to_ordered_id.pkl 2. ordered_id_to_user_id.pkl 3. artist_id_to_ordered_id.pkl 4. ordered_id_to_artist_id.pkl 5.3. Model Selection Result : No precision @10 map@10 ndcg@10 auc@10 model 1 0.135773 0.062366 0.134182 0.565975 AlternatingLeastSquares 2 0.112814 0.053603 0.115200 0.553911 BayesianPersonalizedRanking 3 0.014199 0.004576 0.013120 0.506782 LogisticMatrixFactorization from several metrics above we can see that AlternatingLeastSquares outperform other models --> move to Hyperparameter Tuning Phase 5.4. Hyperparameter Tuning In this process we will find the best parameters pair for our best selected models, AlternatingLeastSquares . Hyperparameters that are available in AlternatingLeastSquares models are : factors number of latent factors, commonly found in matrix factorization model, including AlternatingLeastSquares , for this hyperparameter we will pick candidate value [100,200,300,400,500] alpha In our AlternatingLeastSquares model we have weight alpha as confidence magnitude from user implicit interactions such as number of clicks, etc. values from alpha we would like to choose, ranging from 0.01 to 1.0 . regularization number of how strong we imposed regularization on weights, this due to the sparsity of the data, we dont want the weight become so big --> prone to overfitting. For this hyperparameter we will try some values ranging from 0.01 to 0.2 Some approach in hyperparameter tuning : GridSearch This approach simply fit all combinations from hyperparameter candidate, let say we have 3 hyperparameter with each candidate value of 3, number of model fitting is 3 3 3 = 27 times fitting.This is not efficient approach, especially with recommender system model with huge size of data. RandomizedSearch This approach perform better than GridSearch approach in terms of computation because it only samples / subset from our hyperparameter. Bayesian Optimization This approach hyperparameter value as Gaussian Process problem where the hyperparemeter value is the product of Surrogate function (such as Gaussian Process), we will use this approach bcause it efficient in terms of computation and provide better result. Don't worry we don't have to understand all right now, and we will not coding it from scratch, we will use optuna package for now. For hyperparameter set up we will perform Cross-Validation with --> K-Fold Cross Validation source Best parameters : 1. factors : 100 2. alpha : 0.5097051938957499 3. regularization : 0.16799704422342204 5.5 Evaluation On final evaluation we measured tuned model on test set, the result precision @10 map@10 ndcg@10 auc@10 0.16635468872652617 0.0844339689737369 0.17261162377361844 0.574831593418623 5.6. Sanity Check on Recommendation 6.Conclusion 6.1. Further Work Using more user oriented metrics such as Diversity, Serendipity, Novelty Using Multistage Approach Apply Graph Data (Friends) Use Metadata as Features,for Using Factorization Machine 7. Product 7.1. API src API (Application Programming Interface) is a set of rules that allows different software applications to communicate with each other. It provides a standardized interface for accessing and utilizing functionalities or data from external services, enabling seamless integration and interoperability between software components. 7.1.1 Running API To run API : cd song_recommender python3 src/api.py check localhost:8000/docs for documentation. 7.1.2 Request Format curl -X 'POST' \\ 'http://localhost:8080/recommend/' \\ -H 'accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"userid\": 2, \"item_to_recommend\": 10 }' 7.1.3 Response Format { \"recommended_artist\": [ \"Michael Jackson\", \"Roxette\", \"a-ha\", \"Lily Allen\", \"Annie Lennox\", \"Bj\u00f6rk\", \"Rammstein\", \"Elvis Presley\", \"Norah Jones\", \"Vangelis\" ] } 8. Experiment with your own.","title":"Home"},{"location":"#1-introduction","text":"","title":"1. Introduction"},{"location":"#11business-understanding","text":"Currently music on-line platform is on the rise. However people still can't fully developed shared their taste. Our Founder feel those and start to develop Music Streaming Platform called ontrack . Our Business is based on Subscription Model. Our Catalogue is Quite Huge contain ~17632 Artists. Our business is on decline, previous month we serve nearly 5000 users, however there is significant churn leaving our platform only having ~2000 users. We are in data science team,asked to assist business development team to tackle this situation.","title":"1.1.Business Understanding"},{"location":"#12-problem-definition","text":"Business Process Problem : User Churn ~60% !","title":"1.2. Problem Definition"},{"location":"#13-business-metrics","text":"Business Metrics : Churn Rate","title":"1.3. Business Metrics"},{"location":"#14-identifying-machine-learning-problem","text":"Process that could be helped with machine learning : Possible Solutions : | No | Solution | Task | Detailed Task | Metrics | |---:|------------------------------------------------------:|---------------:|-----------------------|--------------------------------------------------------| | 1 | Predict number of user play count on each artist | Regression | Count Regression | Prediction Error (RMSE,MAE,etc) | | 2 | Predict whether user will like the artist or not | Classification | Binary Classification | Decision Support Metrics (Precision,Recall,AUC,F1,etc) | | 3 | Predict condfidence scale (0-1) how user like an item | Regression | - | Prediction Error (RMSE,MAE,etc) | | 4 | Predict the ranking from user to artists | Ranking | Pairwise Ranking | Ranking Metrics (ex : NDCG,MAP,MRR,etc) |","title":"1.4. Identifying Machine Learning Problem"},{"location":"#15-objective-metrics","text":"","title":"1.5 Objective Metrics"},{"location":"#2-related-work","text":"Hu, Y., Ogihara, M.: Nextone player: A music recommendation system based on user behaviour. In: Int. Society for Music Information Retrieval Conf. (ISMIR\u201911) (2011) Hariri, N., Mobasher, B., Burke, R.: Context-aware music recommendation based on latenttopic sequential patterns. In: Proceedings of the sixth ACM conference on Recommender systems, pp. 131\u2013138. ACM (2012)","title":"2. Related Work"},{"location":"#3-dataset-and-features","text":"The dataset obtained from http://www.last.fm, online music system. The dataset itself contains several files artists.dat Contains features : - `name` - `url` - `pictureURL` tags.dat Contains features : - `tagID` - `tagValue` user_artists.dat Contains features : - `userID` - `artistsID` - `pictureURL` user_friends.dat Contains features : - `name` - `url` - `pictureURL` user_taggedartists.dat Contains features : - `name` - `url` - `pictureURL`","title":"3. Dataset and Features"},{"location":"#4-methods","text":"","title":"4. Methods"},{"location":"#41-recommender-system-introduction","text":"Recomender system Problem We have implicit feedback dataset that reflects number of user plays from certain artist. Given those utility matrix we will recommend to each user what artist they might like. The recommendation will be in form such as 1. \"Since you listen to artist X\" --> give list 2. etc. Since we have enough utility matrix / implicit feedback we will start with collaborative filtering approach. Collaborative filtering approach can be divided into several approaches","title":"4.1. Recommender System Introduction"},{"location":"#42baseline-popularity-recommendation","text":"","title":"4.2.Baseline (Popularity Recommendation)"},{"location":"#43-alternating-least-square-implicit-feedback-matrix-factorization","text":"Hu, Yifan, Yehuda Koren, and Chris Volinsky. 2008. \u201cCollaborative Filtering for Implicit Feedback Datasets.\u201d In 2008 Eighth IEEE International Conference on Data Mining, 263\u201372. IEEE.","title":"4.3. Alternating Least Square (Implicit Feedback Matrix Factorization)"},{"location":"#43-bayesian-personalized-ranking","text":"Rendle, Steffen, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. \u201cBPR: Bayesian Personalized Ranking from Implicit Feedback.\u201d In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, 452\u201361. AUAI Press.","title":"4.3. Bayesian Personalized Ranking"},{"location":"#44-logistic-matrix-factorization","text":"Johnson, Christopher C. 2014. \u201cLogistic Matrix Factorization for Implicit Feedback Data.\u201d Advances in Neural Information Processing Systems 27.","title":"4.4. Logistic Matrix Factorization"},{"location":"#5experiments-results-discussion","text":"","title":"5.Experiments / Results / Discussion"},{"location":"#51-data-splitting-strategy","text":"","title":"5.1. Data Splitting Strategy"},{"location":"#52-data-preprocessing","text":"","title":"5.2. Data Preprocessing"},{"location":"#521-mapping-userid-artistsid-into-ordered-id","text":"Our data requirement is in utility matrix form, it would be hard to access each element in utility matrix since utility matrix has ordered id. We need to create mapping for both userID, artistsID to orderedID and vice versa.Our Mapping is in python dictionary object. user_id_to_ordered_id = { userID:ordereduserID } example : user_id_to_ordered_id = { 2:1 } for later usage (such as : API) we will serialize object using joblib.dump function as pickle file ( .pkl ), named : 1. user_id_to_ordered_id.pkl 2. ordered_id_to_user_id.pkl 3. artist_id_to_ordered_id.pkl 4. ordered_id_to_artist_id.pkl","title":"5.2.1 Mapping  userID &amp; artistsID into Ordered ID"},{"location":"#53-model-selection","text":"Result : No precision @10 map@10 ndcg@10 auc@10 model 1 0.135773 0.062366 0.134182 0.565975 AlternatingLeastSquares 2 0.112814 0.053603 0.115200 0.553911 BayesianPersonalizedRanking 3 0.014199 0.004576 0.013120 0.506782 LogisticMatrixFactorization from several metrics above we can see that AlternatingLeastSquares outperform other models --> move to Hyperparameter Tuning Phase","title":"5.3. Model Selection"},{"location":"#54-hyperparameter-tuning","text":"In this process we will find the best parameters pair for our best selected models, AlternatingLeastSquares . Hyperparameters that are available in AlternatingLeastSquares models are : factors number of latent factors, commonly found in matrix factorization model, including AlternatingLeastSquares , for this hyperparameter we will pick candidate value [100,200,300,400,500] alpha In our AlternatingLeastSquares model we have weight alpha as confidence magnitude from user implicit interactions such as number of clicks, etc. values from alpha we would like to choose, ranging from 0.01 to 1.0 . regularization number of how strong we imposed regularization on weights, this due to the sparsity of the data, we dont want the weight become so big --> prone to overfitting. For this hyperparameter we will try some values ranging from 0.01 to 0.2 Some approach in hyperparameter tuning : GridSearch This approach simply fit all combinations from hyperparameter candidate, let say we have 3 hyperparameter with each candidate value of 3, number of model fitting is 3 3 3 = 27 times fitting.This is not efficient approach, especially with recommender system model with huge size of data. RandomizedSearch This approach perform better than GridSearch approach in terms of computation because it only samples / subset from our hyperparameter. Bayesian Optimization This approach hyperparameter value as Gaussian Process problem where the hyperparemeter value is the product of Surrogate function (such as Gaussian Process), we will use this approach bcause it efficient in terms of computation and provide better result. Don't worry we don't have to understand all right now, and we will not coding it from scratch, we will use optuna package for now. For hyperparameter set up we will perform Cross-Validation with --> K-Fold Cross Validation source Best parameters : 1. factors : 100 2. alpha : 0.5097051938957499 3. regularization : 0.16799704422342204","title":"5.4. Hyperparameter Tuning"},{"location":"#55-evaluation","text":"On final evaluation we measured tuned model on test set, the result precision @10 map@10 ndcg@10 auc@10 0.16635468872652617 0.0844339689737369 0.17261162377361844 0.574831593418623","title":"5.5 Evaluation"},{"location":"#56-sanity-check-on-recommendation","text":"","title":"5.6. Sanity Check on Recommendation"},{"location":"#6conclusion","text":"","title":"6.Conclusion"},{"location":"#61-further-work","text":"Using more user oriented metrics such as Diversity, Serendipity, Novelty Using Multistage Approach Apply Graph Data (Friends) Use Metadata as Features,for Using Factorization Machine","title":"6.1. Further Work"},{"location":"#7-product","text":"","title":"7. Product"},{"location":"#71-api","text":"src API (Application Programming Interface) is a set of rules that allows different software applications to communicate with each other. It provides a standardized interface for accessing and utilizing functionalities or data from external services, enabling seamless integration and interoperability between software components.","title":"7.1. API"},{"location":"#711-running-api","text":"To run API : cd song_recommender python3 src/api.py check localhost:8000/docs for documentation.","title":"7.1.1 Running API"},{"location":"#712-request-format","text":"curl -X 'POST' \\ 'http://localhost:8080/recommend/' \\ -H 'accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ \"userid\": 2, \"item_to_recommend\": 10 }'","title":"7.1.2 Request Format"},{"location":"#713-response-format","text":"{ \"recommended_artist\": [ \"Michael Jackson\", \"Roxette\", \"a-ha\", \"Lily Allen\", \"Annie Lennox\", \"Bj\u00f6rk\", \"Rammstein\", \"Elvis Presley\", \"Norah Jones\", \"Vangelis\" ] }","title":"7.1.3 Response Format"},{"location":"#8-experiment-with-your-own","text":"","title":"8. Experiment with your own."}]}